{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DICOM Crawling Code\n",
    "Given a list of directories, this script will resave all data from DICOMs stored in those folders. The pixel data will be stored in ``pixel_data.h5`` and the metadata from the DICOM headers will be stored in ``metadata.csv``. The HDF5 and CSV files support efficient data reading and evaluation. Note that running this notebook is equivalent to calling ``run_crawler.py`` from the command line.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by importing required packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawler_utils import dicom_crawl\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of directories, each of which should contain DICOMs. All DICOMs directly inside these directories will be processed.\n",
    "# Note that we won't parse through these directories to find subdirectories, we'll ignore anything that isn't a directory in this list, and we'll ignore any files that aren't DICOM files found in these directories.\n",
    "dicom_folders = ['/data_storage/train_images','/data_storage/test_images']\n",
    "\n",
    "# Define a directory to store outputs\n",
    "storage_folder = os.getcwd()\n",
    "\n",
    "# Define a unique identifier for output filenames; can be None\n",
    "# ex: output_id = 'study1' results in outputs 'pixel_data_study1.h5' and 'metadata_study1.csv'\n",
    "# ex: output_id = None results in outputs 'pixel_data.h5' and 'metadata.csv'\n",
    "output_id = 'CT'\n",
    "\n",
    "# Define number of processors; note that if saving 2d scans, parallelization will be ignored\n",
    "n_procs = 1\n",
    "\n",
    "# Turn on/off functionality to create h5 of all pixel data; writing pixel data increases run time significantly\n",
    "# Set to True to write all pixel data, False to write no pixel data\n",
    "write_pixeldata = True \n",
    "\n",
    "# Choose whether to evaluate 3d series or 2d images\n",
    "# If eval_3d_scans = True, dicom_crawl() will find all scans with the same series instance UID and stack them in order into a 3d image, then save the 3d stack in the h5 and save one line of metadata/scan\n",
    "# If eval_3d_scans = False, dicom_crawl() will save each individual DICOM file's pixel data as a 2d image in the h5 file and each DICOM file's metadata will be written to a CSV\n",
    "eval_3d_scans = True\n",
    "\n",
    "# Choose whether to parallelize over the folders by setting par_over_folder = True, or over the scans within a folder by setting par_over_folder = 0\n",
    "# Note this parallelization is only used when evaluating 3d data.\n",
    "# If you have many folders in dicom_folders, each with O(1) scan, set the parameter below to True\n",
    "# If you have many scans per folder, set the parameter below to False to have the code parallelize over scans within a folder\n",
    "par_over_folder = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run DICOM crawling code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of previously stored scans:  0\n",
      "Starting DICOM crawling...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/35 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 31/35 [00:53<00:14,  3.62s/it]/home/hoopersm/DICOMDataExtractor/crawler_utils.py:195: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  new_metadata = pd.read_csv(metadata_storage_fn).append(new_metadata, ignore_index=True)\n",
      "35it [01:06,  1.90s/it][01:06<00:00,  3.85s/it]\n",
      "100%|██████████| 35/35 [01:06<00:00,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running DICOM crawling code.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Crawl dicoms\n",
    "dicom_crawl(dicom_folders, storage_folder, output_id, n_procs, write_pixeldata, eval_3d_scans, par_over_folder)\n",
    "print(\"Finished running DICOM crawling code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dicomEnv",
   "language": "python",
   "name": "dicomenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
